{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujathasivaraman/mlai/blob/main/cnn_chicken.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "aymTArJ1_VK0",
        "outputId": "f4637e3f-94bc-4156-ae44-f26d543ac0be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-images-download in /usr/local/lib/python3.11/dist-packages (2.8.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (from google-images-download) (4.34.1)\n",
            "Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium->google-images-download) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium->google-images-download) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium->google-images-download) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.11/dist-packages (from selenium->google-images-download) (2025.6.15)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.11/dist-packages (from selenium->google-images-download) (4.14.0)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium->google-images-download) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium->google-images-download) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium->google-images-download) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium->google-images-download) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium->google-images-download) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium->google-images-download) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium->google-images-download) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium->google-images-download) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium->google-images-download) (0.16.0)\n",
            "\n",
            "Item no.: 1 --> Item name = chickens\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "\n",
            "Errors: 0\n",
            "\n",
            "Thumbnails for 'chickens' downloaded successfully!\n"
          ]
        }
      ],
      "source": [
        "#@title IGNORE Google images download code\n",
        "!pip install google-images-download\n",
        "from google_images_download import google_images_download\n",
        "\n",
        "def download_thumbnails(query, limit=10, output_dir='chickens\\downloads'):\n",
        "    response = google_images_download.googleimagesdownload()\n",
        "    arguments = {\n",
        "        \"keywords\": query,\n",
        "        \"limit\": limit,\n",
        "        \"print_urls\": True,\n",
        "        \"size\": \"medium\",  # Ensures thumbnails or smaller images\n",
        "        \"output_directory\": output_dir,\n",
        "        \"format\": \"jpg\"\n",
        "    }\n",
        "    try:\n",
        "        response.download(arguments)\n",
        "        print(f\"Thumbnails for '{query}' downloaded successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "download_thumbnails(\"chickens\", limit=1)\n",
        "\n",
        "\n",
        "# ext = ext if ext in ['jpg', 'jpeg', 'png', 'webp'] else 'jpg'\n",
        "#         # Extract and clean file extension\n",
        "#         ext_match = re.search(r'\\.(jpg|jpeg|png|webp)', url, re.IGNORECASE)\n",
        "#         ext = ext_match.group(1).lower() if ext_match else 'jpg'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RUN in GPU mode\n",
        "# {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "#@markdown ##**BEFORE RUNNING ANY CODE, please change your Hardware Accelerator to GPU to train faster!**</h2>\n",
        "#@markdown 1. Click on the **Runtime** menu at the top of the screen.\n",
        "#@markdown 2. Click **Change Runtime Type**.\n",
        "#@markdown 3. Choose **T4 GPU** under **Hardware Accelerator**.\n",
        "\n",
        "#@markdown Once you've done that, run this code cell to check you're correctly connected!\n",
        "\n",
        "import tensorflow as tf\n",
        "from IPython.display import Markdown\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "  display(Markdown(\"###✅ GPU connected!\"))\n",
        "else:\n",
        "  display(Markdown(\"\"\"\n",
        "###❌ No GPU found!\n",
        "If you're running into GPU limits when you try to switch, here are some suggestions:\n",
        "  - Wait 12-24 hours for the limits to reset.\n",
        "  - Share your copy of the notebook with another Google account that hasn't met the limit, and work through the notebook with that account.\n",
        "  - Look into a paid subscription or paying for compute units as you go.\n",
        "  \"\"\"))"
      ],
      "metadata": {
        "id": "oRDgWpMpYXz9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "a7c84783-aafe-46c6-88cd-bb6e1bf40c03"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n###❌ No GPU found!\nIf you're running into GPU limits when you try to switch, here are some suggestions:\n  - Wait 12-24 hours for the limits to reset.\n  - Share your copy of the notebook with another Google account that hasn't met the limit, and work through the notebook with that account.\n  - Look into a paid subscription or paying for compute units as you go.\n  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Local Drive :  Run this to load images and imports! {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np  # Added for numerical operations\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Constants\n",
        "IMG_SHAPE = (150, 150)  # Tuple format\n",
        "BATCH_SIZE = 32  # More manageable batch size\n",
        "zip_path = '/content/drive/My Drive/Dataset/chicken_notachicken.zip'\n",
        "# extract_dir = '/content/drive/My Drive/Dataset/cats_and_dogs_filtered_extracted'\n",
        "# zip_path = '/content/drive/My Drive/Dataset/cats_and_dogs_filtered.zip'\n",
        "extract_dir = '/content/drive/My Drive/Dataset'\n",
        "\n",
        "data_dir = '/content/drive/My drive/Dataset'\n",
        "# img_size = (150,150)\n",
        "# batch_size = 32\n",
        "\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     train_dir,\n",
        "#     target_size=IMG_SHAPE,\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     class_mode='binary',\n",
        "#     shuffle=True\n",
        "# )\n",
        "\n",
        "# train_dataset = image_dataset_from_directory(\n",
        "#     data_dir,\n",
        "#     validation_split=0.2,\n",
        "#     subset=\"training\",\n",
        "#     seed=123,\n",
        "#     image_size = IMG_SHAPE,\n",
        "#     batch_size= BATCH_SIZE\n",
        "# )\n",
        "\n",
        "# validation_dataset = image_dataset_from_directory(\n",
        "#     data_dir,\n",
        "#     validation_split=0.2,\n",
        "#     subset=\"validation\",\n",
        "#     seed=123,\n",
        "#     image_size=img_size,\n",
        "#     batch_size=batch_size\n",
        "# )\n",
        "#train_generator = train_datagen.flow_from_directory(\n",
        "train_generator = image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    image_size=IMG_SHAPE,\n",
        "    seed = '123',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    interpolation ='bilinear',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed = '123',\n",
        "    image_size=IMG_SHAPE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "#    class_mode='binary',\n",
        "    interpolation ='bilinear',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# # Verify class indices\n",
        "# print(\"Class indices:\", train_generator.class_indices)\n",
        "\n",
        "# # Optional: Load sample batch for inspection\n",
        "# sample_images, sample_labels = next(train_generator)\n",
        "# print(\"Sample batch shape:\", sample_images.shape)\n",
        "# print(\"Sample labels shape:\", sample_labels.shape)\n",
        "\n",
        "# Visualize sample images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(sample_images[i])\n",
        "    plt.title(f\"Label: {sample_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "8qcX0xmJZQnL",
        "outputId": "deaef7fe-eab5-4a79-ee16-8006703ee34f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Could not find directory /content/drive/My drive/Dataset",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-36-2356600550.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#train_generator = train_datagen.flow_from_directory(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m train_generator = image_dataset_from_directory(\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/image_dataset_utils.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"inferred\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    766\u001b[0m   \"\"\"\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     raise errors.NotFoundError(\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Could not find directory /content/drive/My drive/Dataset"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure dataset for performance\n",
        "AUTOTUNE=tf.data.AUTOTUNE\n",
        "train_dataset=train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset=validation_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "7Bq7VcHZsVWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load pretrained model\n",
        "pretrained_model = tf.kera.applications.MobileNetV2(input_shape=(150,150,3),include_top=False, weights='imagenet')"
      ],
      "metadata": {
        "id": "8CDT7U3_r1tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title freeze the convuolutional Base\n",
        "pretrained_model.trainable= False\n"
      ],
      "metadata": {
        "id": "hrrgpH1otH8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Add a classification head\n",
        "model = models.Sequential([pretrained_model, layers.GlobalAveragePooling2D(),layers.Dense(1)])"
      ],
      "metadata": {
        "id": "y_lsj9smtTNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Complile the model\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001,loss=tf.keras.losses.binary_crossentropy(from_logits=True),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jS3-XZqDtpdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train the model\n",
        "history=model.fit(train_dataset,epochs=10,validation_data=validation_dataset)"
      ],
      "metadata": {
        "id": "fK60V-xouPo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Validate the model\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(acc,label='Training Accuracy')\n",
        "plt.plot(val_acc,label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(acc,label='Training Loss')\n",
        "plt.plot(val_acc,label='Validation Loss')\n",
        "plt.legend(loc='Upper right')\n",
        "plt.ylabel('Cross Entrophy')\n",
        "plt.ylim(min[0,1.0])\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "LgRbj1MJufr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preprocess the Image\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def load_and_preprocess_image(img_path):\n",
        "    # Load the image file, resizing it to the input size of our model\n",
        "    img = image.load_img(img_path, target_size=img_size)\n",
        "\n",
        "    # Convert the image to array\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Normalize the image pixels\n",
        "    img_array /= 255.0\n",
        "\n",
        "    # Expand dimensions to fit the batch size\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "SzjREbx8wsO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make predictions\n",
        "def predict_image(model, img_path):\n",
        "    # Preprocess the image\n",
        "    img_array = load_and_preprocess_image(img_path)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "    # Decode the predictions to the original labels\n",
        "    predicted_label = \"chicken\" if predictions[0] > 0 else \"notachicken\"\n",
        "\n",
        "    return predicted_label"
      ],
      "metadata": {
        "id": "gdebJ5wSwyp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WpGNv6oj1afi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@title Test with real picture\n",
        "img_path = \"path_to_your_photo\"  # Replace with the path of your image\n",
        "predicted_label = predict_image(model, img_path)\n",
        "\n",
        "print(f\"The model predicts that the image is a {predicted_label}\")"
      ],
      "metadata": {
        "id": "ObbWtzz8w5kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title IGNORE Load data,  Display pictures\n",
        "#@title Load our data\n",
        "data_raw, labels_raw = load_data()\n",
        "data = data_raw.astype(float)\n",
        "labels = categorical_to_numpy(labels_raw)\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(data, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "### WRITE YOUR CODE BELOW: Print the image data and its shape using the shape attribute!\n",
        "#plot_one_image(data_raw, labels_raw, 300) # Play around with the number!\n",
        "def show_image(image_data, label, index):\n",
        "    image = image_data[index].reshape(32, 32, 3)  # assuming CIFAR-style 32x32 RGB\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Label: {label[index]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "# Plot 10 images in a 2x5 grid\n",
        "plt.figure(figsize=(12, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    show_image(data_raw, labels_raw, i)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AOz3dAiq_Syn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display data or images\n",
        "index = np.random.randint(len(cd_train_inputs))\n",
        "plt.imshow(cd_train_inputs[index] / 255)\n",
        "plt.show()\n",
        "print(\"Label:\", cd_train_labels[index])\n",
        "\n",
        "# Optional: Load sample batch for inspection\n",
        "sample_images, sample_labels = next(train_generator)\n",
        "print(\"Sample batch shape:\", sample_images.shape)\n",
        "print(\"Sample labels shape:\", sample_labels.shape)\n",
        "\n",
        "# Visualize sample images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(sample_images[i])\n",
        "    plt.title(f\"Label: {sample_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NddAY0ALY3vP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}