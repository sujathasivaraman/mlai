{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPAK9XUAoU03liQt4UqRqkw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujathasivaraman/mlai/blob/main/chicken_cnn_binaryclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSQF-M_AIDjO"
      },
      "outputs": [],
      "source": [
        "#@title RUN in GPU mode\n",
        "# {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "#@markdown ##**BEFORE RUNNING ANY CODE, please change your Hardware Accelerator to GPU to train faster!**</h2>\n",
        "#@markdown 1. Click on the **Runtime** menu at the top of the screen.\n",
        "#@markdown 2. Click **Change Runtime Type**.\n",
        "#@markdown 3. Choose **T4 GPU** under **Hardware Accelerator**.\n",
        "\n",
        "#@markdown Once you've done that, run this code cell to check you're correctly connected!\n",
        "\n",
        "import tensorflow as tf\n",
        "from IPython.display import Markdown\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "  display(Markdown(\"###✅ GPU connected!\"))\n",
        "else:\n",
        "  display(Markdown(\"\"\"\n",
        "###❌ No GPU found!\n",
        "If you're running into GPU limits when you try to switch, here are some suggestions:\n",
        "  - Wait 12-24 hours for the limits to reset.\n",
        "  - Share your copy of the notebook with another Google account that hasn't met the limit, and work through the notebook with that account.\n",
        "  - Look into a paid subscription or paying for compute units as you go.\n",
        "  \"\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Chickens Google Drive :  Run this to load images and imports! {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np  # Added for numerical operations\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Constants\n",
        "IMG_SHAPE = (160, 160)  # Tuple format\n",
        "BATCH_SIZE = 32  # More manageable batch size\n",
        "zip_path = '/content/drive/My Drive/Dataset/chicken_notachicken.zip'\n",
        "# extract_dir = '/content/drive/My Drive/Dataset/cats_and_dogs_filtered_extracted'\n",
        "# zip_path = '/content/drive/My Drive/Dataset/cats_and_dogs_filtered.zip'\n",
        "extract_dir = '/content/drive/MyDrive/Dataset'\n",
        "\n",
        "# Create extraction directory\n",
        "os.makedirs(extract_dir, exist_ok=True)  # Safer directory creation\n",
        "\n",
        "# # Extract ZIP\n",
        "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Dataset directories\n",
        "base_dir = os.path.join(extract_dir, 'chicken_notachicken')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "print(\"Base directory:\", base_dir)\n",
        "print(\"Train Directory: \", train_dir)\n",
        "print(\"Validation Directory: \", validation_dir)\n",
        "print(\"Test Directory: \", test_dir)\n",
        "\n",
        "# Verify directories\n",
        "assert os.path.exists(train_dir), f\"Train directory not found: {train_dir}\"\n",
        "assert os.path.exists(validation_dir), f\"Validation directory not found: {validation_dir}\"\n",
        "assert os.path.exists(test_dir), f\"Test directory not found: {test_dir}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MR_2LxZIHoe",
        "outputId": "53692b07-9dc2-4dff-ae41-c120bbfbce72"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Base directory: /content/drive/MyDrive/Dataset/chicken_notachicken\n",
            "Train Directory:  /content/drive/MyDrive/Dataset/chicken_notachicken/train\n",
            "Validation Directory:  /content/drive/MyDrive/Dataset/chicken_notachicken/validation\n",
            "Test Directory:  /content/drive/MyDrive/Dataset/chicken_notachicken/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Chicken Keras create data generators with normalization\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "# Create data generators with normalization\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "TJBJocOuIO0C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Chicken : Keras flow from directory : loading and augmenting image datasets\n",
        "train_data = next(train_datagen.flow_from_directory(\n",
        "    batch_size=76,\n",
        "    directory=train_dir,\n",
        "    shuffle=True,\n",
        "    target_size=IMG_SHAPE, #(150,150)\n",
        "    class_mode='binary')\n",
        ")\n",
        "\n",
        "validation_data = next(val_datagen.flow_from_directory(\n",
        "    batch_size=5,\n",
        "    directory=validation_dir,\n",
        "    shuffle=False,\n",
        "    target_size=IMG_SHAPE, #(150,150)\n",
        "    class_mode='binary')\n",
        ")\n",
        "\n",
        "test_data = next(test_datagen.flow_from_directory(\n",
        "    batch_size=20,\n",
        "    directory=test_dir,\n",
        "    shuffle=False,\n",
        "    target_size=IMG_SHAPE, #(150,150)\n",
        "    class_mode=None)\n",
        ")"
      ],
      "metadata": {
        "id": "7avv_IvgIRF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Chicken : train/validate/test\n",
        "cd_train_inputs, cd_train_labels = train_data\n",
        "cd_validation_inputs, cd_validation_labels = validation_data\n",
        "# [the test data doesnt have two folders like chicken or notachicken it has only data folder]\n",
        "cd_test_inputs= test_data\n",
        "#cd_test_inputs, cd_test_labels = test_data"
      ],
      "metadata": {
        "id": "LZLOqNvEISDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Chicken : Experiment ROC - MobileNetV2\n",
        "from tensorflow.keras import layers, models, optimizers, metrics\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load pre-trained MobileNetV2 as feature extractor\n",
        "pretrained_MobileNetV2model = MobileNetV2(\n",
        "    input_shape=(160, 160, 3),       # your input image size\n",
        "    include_top=False,               # exclude ImageNet classification head\n",
        "    weights='imagenet',              # load pre-trained weights\n",
        "    pooling=None                    # no pooling, we'll add it manually\n",
        ")\n",
        "\n",
        "# Freeze the MobileNetV2 layers for feature extraction (optional)\n",
        "pretrained_MobileNetV2model.trainable = False\n",
        "\n",
        "# Build the new model on top of MobileNetV2\n",
        "modelMobileNetV2 = models.Sequential([\n",
        "    pretrained_MobileNetV2model,         # Backbone\n",
        "    layers.GlobalAveragePooling2D(),     # Reduces 4D tensor to 2D\n",
        "    layers.Dropout(0.2),                 # Optional: helps prevent overfitting\n",
        "#    layers.Dense(1, activation=None)     # Raw logits (use activation='sigmoid' if not using from_logits=True)\n",
        "    layers.Dense(1, activation='sigmoid')     # Raw logits (use activation='sigmoid' if not using from_logits=True)\n",
        "])\n",
        "modelMobileNetV2.compile(\n",
        "     optimizer=optimizers.Adamax(\n",
        "         learning_rate=0.0001,       # Learning rate\n",
        "         beta_1=0.9,                 # Exponential decay rate for the 1st moment estimates\n",
        "         beta_2=0.999,               # Exponential decay rate for the 2nd moment estimates\n",
        "         epsilon=1e-07,              # Small constant for numerical stability\n",
        "         name='Adamax'\n",
        "     ),\n",
        "     loss=tf.keras.losses.BinaryCrossentropy(\n",
        "         #from_logits=True,           # Set to True if last layer has no activation (e.g., no sigmoid)\n",
        "         from_logits=False,           # Set to True if last layer has no activation (e.g., no sigmoid)\n",
        "         label_smoothing=0.0         # Optional: smooth labels to prevent overconfidence\n",
        "     ),\n",
        "     metrics=[\n",
        "         'accuracy',                            # Basic classification accuracy\n",
        "         #metrics.Precision(name='precision'),   # Optional: precision metric\n",
        "         #metrics.Recall(name='recall'),         # Optional: recall metric\n",
        "         #metrics.AUC(name='auc'),               # Optional: area under ROC\n",
        "     ],\n",
        "     weighted_metrics=None,         # Optional: metrics evaluated with sample_weight\n",
        "     run_eagerly=False,             # Run in eager mode (useful for debugging)\n",
        "     steps_per_execution=1          # Steps per function call for performance tuning\n",
        " )\n",
        "\n",
        "##############Optional if you are using testdata\n",
        "#MobileNetV2_predictions = modelMobileNetV2.predict(test_data)\n",
        "\n",
        "# pred_cat = []\n",
        "# # for i in range(len(predictions)):\n",
        "# #   print(predictions[i])\n",
        "\n",
        "# for i in range(len(predictions)):\n",
        "#   if predictions[i] < 0:\n",
        "#     pred_cat.append(\"Chicken\")\n",
        "#   if predictions[i] > 0:\n",
        "#     pred_cat.append(\"Not a Chicken\")\n",
        "#   print(predictions[i])\n",
        "# pred_cat\n",
        "###############################################\n",
        "\n",
        "# Train the model\n",
        "MobileNetV2_history = modelMobileNetV2.fit(\n",
        "    cd_train_inputs,                     # Training input data (e.g., images)\n",
        "    cd_train_labels,                     # Training labels (binary or one-hot)\n",
        "    batch_size=32,                         # Number of samples per gradient update\n",
        "    epochs=10,                             # Number of epochs to train\n",
        "    verbose=1,                             # 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
        "    callbacks=None,                        # List of Keras callbacks (e.g., EarlyStopping, ModelCheckpoint)\n",
        "    #validation_split=0.0,                  # Use this % of training data for validation (instead of validation_data)\n",
        "    validation_data=(cd_validation_inputs, cd_validation_labels),  # Data on which to evaluate the loss and metrics\n",
        "    #validation_data=(cd_test_inputs, abs(MobileNetV2_predictions)),  # Data on which to evaluate the loss and metrics\n",
        "    shuffle=True,                          # Whether to shuffle training data before each epoch\n",
        "    class_weight=None,                     # Optional dict mapping class indices to weights (e.g., {0: 1.0, 1: 3.0})\n",
        "    sample_weight=None,                    # Optional array of weights for individual training samples\n",
        "    initial_epoch=0,                       # Epoch at which to start training (useful when resuming)\n",
        "    steps_per_epoch=None,                 # Use for generators/datasets; otherwise leave as None\n",
        "    validation_steps=None,                # Same as above for validation set\n",
        "    validation_batch_size=None,           # Batch size for validation data\n",
        "    validation_freq=1,                    # Evaluate validation data every n epochs\n",
        "    #max_queue_size=10,                    # Generator prefetch queue\n",
        "    #workers=1,                             # Number of CPU threads for generators\n",
        "    #use_multiprocessing=False             # Use multiprocessing when using data generators\n",
        ")\n",
        "\n",
        "#@title Chicken : Accuracy and Loss for modelhistory (MobileNetV2, EfficientB0, VGG16)\n",
        "acc = mobilenetv2_history .history['accuracy']\n",
        "val_acc = mobilenetv2_history.history['val_accuracy']\n",
        "loss = mobilenetv2_history.history['loss']\n",
        "val_loss = mobilenetv2_history.history['val_loss']\n",
        "\n",
        "############################################################\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "############################################################\n",
        "\n",
        "# After training, generate predictions (example for ROC curve calculation)\n",
        "MobileNetV2_predictions = modelMobileNetV2.predict(cd_validation_inputs)\n",
        "#curve_prediction = tf.sigmoid(MobileNetV2_predictions).numpy()\n",
        "curve_prediction= MobileNetV2_predictions\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "print(len(test_data))\n",
        "for i in range(min(9, len(test_data))): # Limit the loop to a maximum of 9 images\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(test_data[i])\n",
        "#    plt.title(f\"Label: {pred_cat[i]}({predictions[i]})\")\n",
        "    plt.title(f\"Label: {curve_prediction[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9J8LepSVIfws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oOvNRnekIyMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Experiment accept image and then predict\n",
        "# First we need to upload the image\n",
        "from google.colab import files\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "# Upload the image file\n",
        "uploaded = files.upload()\n",
        "predicted_label=\"\"\n",
        "\n",
        "# Get the uploaded filename\n",
        "img_name = next(iter(uploaded))\n",
        " # Use your actual model variable\n",
        "# Now predict using the model\n",
        "predicted_label = predict_image(modelMobileNetV2, img_name)\n",
        "#predicted_label = predict_image(modelvgg16, img_name)\n",
        "\n",
        "print(f\"Sujatha : The model predicts that the image is a {predicted_label}\")\n",
        "\n",
        "# Display the image\n",
        "display(Image(img_name))\n",
        "\n",
        "# Clean up the uploaded file\n",
        "os.remove(img_name)\n",
        "\n",
        "#@title Experiment: Upload Image and Predict\n",
        "# # Step 1: Import Necessary Libraries\n",
        "# from google.colab import files\n",
        "from IPython.display import Image, display, clear_output\n",
        "# import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "# import os\n",
        "\n",
        "# # Define image shape expected by your model\n",
        "# IMG_SHAPE = (150, 150)  # Update this to match your model's input shape\n",
        "\n",
        "# # Step 2: Create an Upload Button\n",
        "# uploader = widgets.FileUpload(\n",
        "#     accept='image/*',  # Accept only image files\n",
        "#     multiple=False  # Do not allow multiple files\n",
        "# )\n",
        "# display(uploader)\n",
        "\n",
        "# # Define the Prediction Function\n"
      ],
      "metadata": {
        "id": "6E4qjL2mJPOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title experiment TPR, NPR, Threshold, ROC, AUC using pretrained models VGG16, MobileNet, EfficientnetB0\n",
        "#Add ROC & AUC Plotting for Binary Classifier\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Apply sigmoid if predictions are raw logits\n",
        "prob_predictions = tf.sigmoid(curve_prediction).numpy()\n",
        "#Krithik exercise for you, generate ROC for testdata using your prediction label array as test labels.\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(cd_validation_labels, prob_predictions)\n",
        "#fpr, tpr, thresholds = roc_curve(cd_validation_labels, vgg16_predictions)\n",
        "#fpr, tpr, thresholds = roc_curve(cd_validation_labels, mobilenetv2_predictions)\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Chicken Classifier')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pQdJYDwBJh6P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}