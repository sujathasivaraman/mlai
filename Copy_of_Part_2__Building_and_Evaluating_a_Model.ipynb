{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujathasivaraman/mlai/blob/main/Copy_of_Part_2__Building_and_Evaluating_a_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEKSC-DdOLu6"
      },
      "source": [
        "<font color=\"#de3023\"><h1><b>üö® REMINDER: MAKE A COPY OF THIS NOTEBOOK, DO NOT EDIT üö®</b></h1></font>\n",
        "\n",
        "<h2>Numerical Classification - Day 2</h2>\n",
        "\n",
        "<p style=\"font-size: 16px;\">\n",
        "Welcome to your second notebook, designed to take your Machine Learning skills to the next level. In this notebook, you‚Äôll deepen your understanding of essential concepts, master the remaining steps for cleaning and formatting your dataset for machine learning, and ultimately build your very first model. Let‚Äôs get started on this exciting next chapter of your journey!\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIYw79SIhujj"
      },
      "source": [
        "# PART 1: Choosing Your Project\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1FGLwKxlZi7iuqD1MnwiuVHr2s9JYG4TT\" height=300>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import Packages\n",
        "\n",
        "%%capture\n",
        "\n",
        "# Data handling and visualization libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Machine learning libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# TensorFlow and Keras for deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Dropout, LSTM, Dense, Input\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
      ],
      "metadata": {
        "id": "BMFxGyOK8bCz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# @title Project Selection\n",
        "Project = \"Heart Disease Detection\" # @param [\"Salary Prediction\",\"Heart Disease Detection\",\"Weather Classification\"]\n",
        "\n",
        "def preprocess_data(project):\n",
        "    project_configs = {\n",
        "        \"Salary Prediction\": {\n",
        "            \"url\": \"https://drive.google.com/uc?id=154i4ydw8b6BApwhFl_Efa8EokK-5WNWe\",\n",
        "            \"label_column\": \"income\",\n",
        "            \"sample\": True\n",
        "        },\n",
        "        \"Heart Disease Detection\": {\n",
        "            \"url\": \"https://drive.google.com/uc?id=1T5jPh95FWdo89xV28RoWNqjpefv_9prN\",\n",
        "            \"label_column\": \"Heart Disease\",\n",
        "            \"fill_na\": {\"Alcohol Intake\": \"None\"},\n",
        "            \"sample\": False\n",
        "        },\n",
        "        \"Weather Classification\": {\n",
        "            \"url\": \"https://drive.google.com/uc?id=1ahDAdF0inxcd6LbHIwyIxAAmWcIsVx3_\",\n",
        "            \"label_column\": \"Weather Type\",\n",
        "            \"sample\": True\n",
        "        }\n",
        "    }\n",
        "\n",
        "    config = project_configs[project]\n",
        "    df = pd.read_csv(config[\"url\"])\n",
        "    df.rename(columns={config[\"label_column\"]: \"label\"}, inplace=True)\n",
        "\n",
        "    if config.get(\"fill_na\"):\n",
        "        for col, value in config[\"fill_na\"].items():\n",
        "            df[col] = df[col].fillna(value)\n",
        "\n",
        "    if config[\"sample\"]:\n",
        "        df = df[~df.isin(['?']).any(axis=1)]\n",
        "        sampled_df = pd.DataFrame()\n",
        "        for cls in df[\"label\"].unique():\n",
        "            sampled_df = pd.concat(\n",
        "                [sampled_df, df[df[\"label\"] == cls].sample(n=600, replace=False, random_state=42)],\n",
        "                axis=0\n",
        "            )\n",
        "        df = sampled_df.reset_index(drop=True)\n",
        "\n",
        "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "    label_encoders = {col: LabelEncoder() for col in categorical_cols}\n",
        "    for col, le in label_encoders.items():\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "    return df, label_encoders\n",
        "\n",
        "df, label_encoders = preprocess_data(Project)"
      ],
      "metadata": {
        "id": "o0sVbAJG68O0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART VI: Training a model\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1xpMpHQwgrs6c6Yn3hLX4n1GPiuBZARfM\" height=400>"
      ],
      "metadata": {
        "id": "ZMPNnmuK2OI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî¢ Convert your labels to one-hot-encodings\n",
        "\n",
        "\n",
        "Different machine learning models require labels to be in specific formats. Behind the scenes, these models perform mathematical operations to predict a label from a set of numerical inputs or features. To train our model and make accurate predictions, we need to ensure that both our features and labels are in numerical form.\n",
        "\n",
        "This was the purpose of Part 1 in this series and in order to streamline the process, we've provided a clean version of ```df``` accessible in this notebook.\n",
        "\n",
        "If we were building a neural network with a package like TensorFlow, our labels would need to be one-hot encoded. In this format, each label is represented as a vector indicating the probability that the provided features belong to each of the categories in our dataset.\n",
        "\n",
        "For models like Logistic Regression through sklearn, however, labels should be represented as single numerical values instead of vectors.\n",
        "\n",
        "Note: Here are a couple examples of how we want to transform our labels.\n",
        "```\n",
        "category 0 -> [1, 0, 0, ...]\n",
        "category 1 -> [0, 1, 0, ...]\n",
        "category 2 -> [0, 0, 1, ...]\n",
        "...\n",
        "```"
      ],
      "metadata": {
        "id": "xEwdRd0D2Ta-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 6A\n",
        "\n",
        "\n",
        "Convert your data's labels (```df['labels']```) into a one-hot encoded vector (```df['labels_ohe']```), as shown in the example above.  Hint: You can use the pandas function [```pd.get_dummies()```](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html). Sometimes a one-hot-encoded version of a variable is called a \"dummy variable\".\n",
        "\n",
        "\n",
        "‚≠ê **BONUS (difficult)** ‚≠ê Try to one-hot encode your labels *without* using the ```get_dummies``` function!"
      ],
      "metadata": {
        "id": "cZRTnhnXR8i9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_ohe = [None] #### YOUR CODE HERE\n",
        "print(\"label #1:\", labels[0])\n",
        "print(\"label #1 converted to OHE:\", labels_ohe[0])"
      ],
      "metadata": {
        "id": "FqGdaNj9FaOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Example Solution\n",
        "labels_ohe = pd.get_dummies(df['label'], dtype = int).to_numpy().tolist() # Using the get_dummies() function to one-hot encode your labels.\n",
        "df['labels_ohe'] = labels_ohe\n",
        "\n",
        "# Bonus: without using the get dummies function\n",
        "# possible_labels = list(set(labels))\n",
        "# label_dict = {possible_labels[i]:i for i in range(len(possible_labels))}\n",
        "# y = np.array([[0 for _ in possible_labels] for _ in labels])\n",
        "# for i,label in enumerate(labels):\n",
        "#   y[i][label_dict[label]] = 1\n",
        "\n",
        "# print(\"label #1:\", labels[0])\n",
        "# print(\"label #1 converted to OHE:\", labels_ohe[0])"
      ],
      "metadata": {
        "id": "5Oq4OmD2QB-Q",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have your one-hot-encoded labels (```labels_ohe```), you can convert these back into a single-label format using a function like [```np.argmax()```](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html).\n",
        "\n",
        "Note: Your df already has a column that contains label in this format (```df['label']```). The below is commented out as it is just a reference code\n"
      ],
      "metadata": {
        "id": "lhFW3bPC5Oy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# labels_single = np.argmax(labels_ohe, axis = 1)\n",
        "# df['label'] = labels_single"
      ],
      "metadata": {
        "id": "qsREEnlU5Oy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üçï Train test split\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1f9HECt_VTMPYTAt-NcpmfCN-cKbv6A6G\" height=300>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g1hN0H9E2KNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, different machine learning packages expect input data in specific formats. For instance, in this notebook, we‚Äôll be using ```sklearn``` to build a Logistic Regression model.\n",
        "\n",
        "In order to simplify the model building piece, we'll split our ```df``` into two separate dataframes (X and y). This will allow us to keep our inputs and label separate."
      ],
      "metadata": {
        "id": "UIuA-1exAQyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['label', 'labels_ohe'])\n",
        "y = df.drop(columns=['labels_ohe'])['label']\n",
        "\n",
        "print(\"Shape of X: \", X.shape)\n",
        "print(\"Shape of y: \", y.shape)"
      ],
      "metadata": {
        "id": "t3_ePTVSAmVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 6B"
      ],
      "metadata": {
        "id": "aYwctCn8SCUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split up your features and labels into a training and testing dataset. Hint: you can use the function ```train_test_split()```."
      ],
      "metadata": {
        "id": "0_5IA6EZSDV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(None, None) ### YOUR CODE HERE\n",
        "\n",
        "print('# of samples in X_train:', len(X_train))\n",
        "print('# of samples in y_train:', len(y_train))\n",
        "print('# of samples in X_test:', len(X_test))\n",
        "print('# of samples in y_test:', len(y_test))"
      ],
      "metadata": {
        "id": "evfJkKivFtOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Example Solution\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "print('# of samples in X_train:', len(X_train))\n",
        "print('# of samples in y_train:', len(y_train))\n",
        "print('# of samples in X_test:', len(X_test))\n",
        "print('# of samples in y_test:', len(y_test))"
      ],
      "metadata": {
        "id": "kKHSmfsxQHFV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_fFdZ6vHSic"
      },
      "source": [
        "### üíª Machine Learning Models\n",
        "\n",
        "You've learned a lot about machine learning models over the past week! Some supervised machine learning models you have touched on have been: K-means classifiers, logistic regression, linear regression, fully connected neural networks, and convolutional neural networks!\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/0/09/Supervised_machine_learning_in_a_nutshell.svg\" height=200>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 6C"
      ],
      "metadata": {
        "id": "hyq_UJq5-PN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example Model Development Walkthrough: Logistic Regression**\n",
        "\n",
        "A very simple classification model that we can use is [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Let us walk through its creation below:\n",
        "\n",
        "\n",
        "```python\n",
        "# Step 1: Initialization\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "# Step 2: Training\n",
        "logistic_model.fit(YOUR X_TRAIN, YOUR Y_TRAIN)\n",
        "\n",
        "# Step 3: Prediction\n",
        "predictions = logistic_model.predict(YOUR X_TEST)\n",
        "\n",
        "# Step 4: Evaluation\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "score = accuracy_score(y_test_c, predictions)\n",
        "print('Logistic Regression Model Accuracy: {:.2%}'.format(score))\n"
      ],
      "metadata": {
        "id": "yJGtCrR1tlZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take some time to build your very first model!"
      ],
      "metadata": {
        "id": "sVm9BQcY-PN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "nb_Re2EA-PN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How well did your model perform? What does this mean?"
      ],
      "metadata": {
        "id": "rYTDgp_N-PN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "reflection = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OxlmfElA-PN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART VII: Evaluating your model\n",
        "\n",
        "<img src=\"https://cdn.prod.website-files.com/6391b5b30283a58cafb3bb77/66645273e7266bd35af722ca_how-to-evaluate-ai.jpeg\" height=400>"
      ],
      "metadata": {
        "id": "Mp17Q7uQrfll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy"
      ],
      "metadata": {
        "id": "zc11i9LvsL5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy is a fundamental metric used to evaluate the performance of a machine learning model. It is defined as the proportion of correct predictions made by the model out of all predictions. Mathematically, it can be expressed as:\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n",
        "$$\n",
        "\n",
        "For classification tasks, accuracy is particularly useful when the dataset is balanced, meaning each class has roughly the same number of samples. It provides a simple way to gauge how well the model is performing."
      ],
      "metadata": {
        "id": "xx9KpvCxseef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 7A"
      ],
      "metadata": {
        "id": "7LO97LqItG1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the ```accuracy_score``` function from sklearn to calculate your accuracy.\n",
        "\n",
        "Note: We've already defined our y_true and y_pred as ```y_test``` and ```predictions``` respectively."
      ],
      "metadata": {
        "id": "FLdKIiAytQCs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ziKWAIcSry9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, accuracy has limitations, especially with imbalanced datasets where one class dominates. In such cases, a model might achieve high accuracy by simply predicting the majority class, even if it performs poorly on the minority class. To address this, additional metrics like precision, recall, and F1-score are often used for a more nuanced evaluation. We'll explore these in the coming sections"
      ],
      "metadata": {
        "id": "IpPdAMSStDRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrices"
      ],
      "metadata": {
        "id": "krnaNXG_s2kT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **Confusion Matrix** is a tabular representation used to evaluate the performance of a classification model. It compares the actual labels with the predicted labels, providing a detailed breakdown of model performance across all classes.\n",
        "\n",
        "The matrix is organized as follows:\n",
        "\n",
        "\\begin{bmatrix}\n",
        "\\text{True Positive (TP)} & \\text{False Positive (FP)} \\\\\n",
        "\\text{False Negative (FN)} & \\text{True Negative (TN)}\n",
        "\\end{bmatrix}\n",
        "\n",
        "1. **True Positive (TP):** The model correctly predicted the positive class.\n",
        "2. **False Positive (FP):** The model incorrectly predicted the positive class when it was actually negative.\n",
        "3. **False Negative (FN):** The model incorrectly predicted the negative class when it was actually positive.\n",
        "4. **True Negative (TN):** The model correctly predicted the negative class.\n",
        "\n",
        "The confusion matrix is particularly valuable for understanding where a model makes errors, such as misclassifying one class as another. It is especially important in imbalanced datasets, where accuracy alone might be misleading. We can also calculate a series of other metrics from our confusion matrix."
      ],
      "metadata": {
        "id": "IV9Qtl1quEab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 7B"
      ],
      "metadata": {
        "id": "IAUc_KwBuK-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the ```confusion_matrix``` function from sklearn to create your matrix. You can then use ```ConfusionMatrixDisplay``` and matplotlib to plot your confusion matrix!\n",
        "\n",
        "Note: We've already defined our y_true and y_pred as ```y_test``` and ```predictions``` respectively."
      ],
      "metadata": {
        "id": "C1yCQPumuK-r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aISM0IituK-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many of each True Positives, True Negatives, False Positives and False Negatives are you seeing?"
      ],
      "metadata": {
        "id": "3U1U5m04tpQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "reflection = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LmABYlmutpQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recall and Precision"
      ],
      "metadata": {
        "id": "Bs6CiTWbsNwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recall** and **Precision** are key metrics derived from the confusion matrix that measure different aspects of a model's performance.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Recall (Sensitivity or True Positive Rate)**\n",
        "\n",
        "Recall quantifies the ability of the model to correctly identify all positive instances. It is defined as:\n",
        "\n",
        "$$\n",
        "\\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}\n",
        "$$\n",
        "\n",
        "High recall indicates that the model correctly captures most of the actual positives but may also include false positives.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Precision (Positive Predictive Value)**\n",
        "Precision measures how many of the positive predictions made by the model are actually correct. It is defined as:\n",
        "\n",
        "$$\n",
        "\\text{Precision} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Positives (FP)}}\n",
        "$$\n",
        "\n",
        "High precision implies the model's positive predictions are highly accurate but may miss some true positives.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**The Precision-Recall Trade-Off**\n",
        "There is an inherent trade-off between precision and recall. Improving one often comes at the cost of the other:\n",
        "\n",
        "- **High Recall, Low Precision:** The model captures most positives but also includes many false positives.\n",
        "- **High Precision, Low Recall:** The model is very confident in its positive predictions but misses many true positives.\n",
        "\n",
        "This trade-off is often controlled by the decision threshold for classifying instances as positive. Adjusting this threshold allows you to balance recall and precision based on the problem's requirements."
      ],
      "metadata": {
        "id": "jFIiGFlevZLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 7C"
      ],
      "metadata": {
        "id": "4WA_GTw7v_Yo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the ```recall_score``` and ```precision_score``` functions from sklearn to generate your metrics\n",
        "\n",
        "Note: We've already defined our y_true and y_pred as ```y_test``` and ```predictions``` respectively."
      ],
      "metadata": {
        "id": "wsJw4C-yv_Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YcsIv9Wvv_Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take your best attempt at explaining what these numbers mean in the context of your chosen project."
      ],
      "metadata": {
        "id": "ZeUwO1uov_Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "reflection = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EVUqL4oWv_Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F1 Score"
      ],
      "metadata": {
        "id": "vOdu9kSwsQOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **F1 Score** is a performance metric that combines **precision** and **recall** into a single value, providing a balanced measure for models where both metrics are important. It is especially useful when dealing with imbalanced datasets, where accuracy might be misleading.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Formula for F1 Score**\n",
        "The F1 Score is the harmonic mean of precision and recall, defined as:\n",
        "\n",
        "$$\n",
        "\\text{F1 Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Interpretation**\n",
        "- A **high F1 Score** indicates that the model achieves both high precision and high recall, effectively balancing the trade-off between the two.\n",
        "- A **low F1 Score** suggests that the model struggles with either precision, recall, or both.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**When to Use F1 Score**\n",
        "The F1 Score is most valuable in scenarios where:\n",
        "1. The cost of false positives and false negatives is significant.\n",
        "2. The dataset is imbalanced, and accuracy alone does not provide meaningful insights into model performance.\n",
        "\n",
        "By focusing on both precision and recall, the F1 Score ensures that a model's predictions are not only accurate but also comprehensive."
      ],
      "metadata": {
        "id": "rRFsmRppwurt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 7D"
      ],
      "metadata": {
        "id": "XdNtUvLvw9Hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the ```f1_score``` function from sklearn to generate your F1 Score.\n",
        "\n",
        "Note: We've already defined our y_true and y_pred as ```y_test``` and ```predictions``` respectively."
      ],
      "metadata": {
        "id": "Jz5Z4f4mw9Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zvLIYxT0w9Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take your best attempt at explaining what these numbers mean in the context of your chosen project."
      ],
      "metadata": {
        "id": "molJ9Gukw9Hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "reflection = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "s73dVe-sw9Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC / AUC"
      ],
      "metadata": {
        "id": "JqLJMTRSsRww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC (Receiver Operating Characteristic)** and **AUC (Area Under the Curve)** are tools used to evaluate the performance of a classification model, particularly in binary classification tasks.\n",
        "\n",
        "**ROC Curve**\n",
        "The ROC curve is a graphical representation of the trade-off between the **True Positive Rate (TPR)** and the **False Positive Rate (FPR)** at various classification thresholds.\n",
        "\n",
        "- **True Positive Rate (Recall):**\n",
        "  \\[\n",
        "  \\text{TPR} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}\n",
        "  \\]\n",
        "\n",
        "- **False Positive Rate:**\n",
        "  \\[\n",
        "  \\text{FPR} = \\frac{\\text{False Positives (FP)}}{\\text{False Positives (FP)} + \\text{True Negatives (TN)}}\n",
        "  \\]\n",
        "\n",
        "The ROC curve plots **TPR** (y-axis) against **FPR** (x-axis) for different thresholds. A model with a better discriminatory ability will have a curve closer to the top-left corner.\n",
        "\n",
        "**AUC (Area Under the Curve)**\n",
        "The AUC is the area under the ROC curve and provides a single value summarizing the model's performance:\n",
        "\n",
        "- **AUC = 1.0:** Perfect model.\n",
        "- **AUC = 0.5:** No discriminatory power (equivalent to random guessing).\n",
        "- **AUC < 0.5:** Worse than random guessing.\n",
        "\n",
        "**Interpretation**\n",
        "- A higher AUC indicates that the model is better at distinguishing between the positive and negative classes across all thresholds.\n",
        "- The ROC-AUC metric is threshold-independent, making it a robust measure for comparing models, especially in datasets with imbalanced classes.\n",
        "\n",
        "By analyzing the ROC curve and AUC, you can assess how well your model differentiates between classes, providing deeper insights beyond accuracy alone."
      ],
      "metadata": {
        "id": "fZJZ7SwZxqN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(None, None)\n",
        "\n",
        "# Calculate the AUC\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\", lw=2, label=\"Random Guessing\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QHk8SMrvx8Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How well did your model perform? What does this mean?"
      ],
      "metadata": {
        "id": "ERDuSmBOtugJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "reflection = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jqTQpoxUtugJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART VIII: Day 2 Homework"
      ],
      "metadata": {
        "id": "9hz2euwC-njS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Explore other baseline models to expand your understanding and improve your approach. Collaborate with your mentor and utilize our [Baseline Model Task Sheet](https://docs.google.com/document/d/12RvGg0MN3PMe9GJNQ3xwcqx9px3vqEYn1Cu1Nwv_1C8/edit?usp=sharing) to stay organized and on track throughout the process.\n",
        "\n",
        "2. Return to your project notebook and implement these steps using your own dataset. Remember that variable names and structures may differ, so be prepared to adapt your code as needed.\n",
        "\n",
        "3. Take time to reflect on your experience. What challenges did you face? What didn‚Äôt work, and what worked well? Don‚Äôt hesitate to seek guidance from your mentor or attend Open Labs‚Äîboilerplate code often requires adjustments for unique datasets! Embrace the challenges; the true beauty of coding lies in solving problems and the immense satisfaction of conquering errors!"
      ],
      "metadata": {
        "id": "26uh97Ut-njT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfwHvs8_-njT"
      },
      "source": [
        "### üéÅ Wrapping Up Day 2\n",
        "\n",
        "üéâ **Congratulations on Building Your First Machine Learning Model!** üéâ  \n",
        "Amazing work! You‚Äôve taken a significant step in your journey by creating your very first machine learning model. This is no small feat‚Äîit‚Äôs the foundation upon which incredible projects are built. üöÄ As you advance your skills and bring your own ideas to life, remember to revisit these notebooks as valuable references to guide your progress.\n",
        "\n",
        "But why stop here? The world of machine learning is vast, and there‚Äôs so much more to explore. Below, you‚Äôll find additional resources and optional enhancements to take your projects to the next level. üåü\n",
        "\n",
        "---\n",
        "\n",
        "### **Expand Your Horizons with Optional Enhancements**\n",
        "\n",
        "- **Dive Into Advanced Models**  \n",
        "   Ready to elevate your projects further? Explore advanced models like Neural Networks and use advanced Python frameworks like PyTorch or Tensorflow to unlock more predictive power and uncover deeper insights.\n",
        "\n",
        "- **Unlock the Power of Ensemble Learning**  \n",
        "   Supercharge your projects with cutting-edge ensemble learning techniques\n",
        "   \n",
        "   üëâ [Ensemble Learning](https://colab.research.google.com/drive/1wNF2sob8CJWaVqGbe4vZQt1EaoPneKHH?usp=drive_link)\n",
        "\n",
        "---\n",
        "\n",
        "### üåü **What‚Äôs Next?**\n",
        "- **Experimentation**: Don‚Äôt be afraid to try new techniques and push the boundaries of what your model can do.\n",
        "- **Iteration**: Refine your skills by iterating on your projects, optimizing performance, and exploring new datasets.  \n",
        "- **Collaboration**: Share your work with mentors, peers, or in Open Labs to gain insights and fresh perspectives.\n",
        "\n",
        "Every model you build and every enhancement you implement is a step closer to mastery. Keep learning, keep growing, and keep building‚Äîyour journey has just begun! üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mxJkGWK576CP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}