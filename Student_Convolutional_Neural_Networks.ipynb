{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujathasivaraman/mlai/blob/main/Student_Convolutional_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiM6gYg0nhkY"
      },
      "source": [
        "<font color=\"red\"><h1><b><u>MAKE A COPY OF THIS NOTEBOOK SO YOUR EDITS ARE SAVED</u></b></h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq-JhCcLpBwS"
      },
      "source": [
        "---\n",
        "---\n",
        "<h1>üê∂<b><i> Convolutional Neural Networks: Improving Our Self-Driving Car's Performance</i></b></h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEK0sVa-WSI1"
      },
      "source": [
        "Welcome back to CC: Conscientious Cars! Today, we'll be improving on our system for distinguishing dogs from roads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKiNM-TVIeyt"
      },
      "outputs": [],
      "source": [
        "#@title {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "#@markdown ##**BEFORE RUNNING ANY CODE, please change your Hardware Accelerator to GPU to train faster!**</h2>\n",
        "#@markdown 1. Click on the **Runtime** menu at the top of the screen.\n",
        "#@markdown 2. Click **Change Runtime Type**.\n",
        "#@markdown 3. Choose **T4 GPU** under **Hardware Accelerator**.\n",
        "\n",
        "#@markdown Once you've done that, run this code cell to check you're correctly connected!\n",
        "\n",
        "import tensorflow as tf\n",
        "from IPython.display import Markdown\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "  display(Markdown(\"###‚úÖ GPU connected!\"))\n",
        "else:\n",
        "  display(Markdown(\"\"\"\n",
        "###‚ùå No GPU found!\n",
        "If you're running into GPU limits when you try to switch, here are some suggestions:\n",
        "  - Wait 12-24 hours for the limits to reset.\n",
        "  - Share your copy of the notebook with another Google account that hasn't met the limit, and work through the notebook with that account.\n",
        "  - Look into a paid subscription or paying for compute units as you go.\n",
        "  \"\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhNVum16scIW"
      },
      "outputs": [],
      "source": [
        "#@title **üèó Setup Cell** {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "#@markdown **Run this to import libraries and download data!**\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# IMPORTS\n",
        "#-------------------------------------------------------------------------------\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, InputLayer\n",
        "from tensorflow.keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Inspirit's util file and discussion exercise answer handler\n",
        "!wget -q \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Modules/inspiritai_util.py\"\n",
        "from inspiritai_util import handle_discussion_response\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# HELPER FUNCTIONS\n",
        "#-------------------------------------------------------------------------------\n",
        "def categorical_to_numpy(labels_in):\n",
        "  labels = []\n",
        "  for label in labels_in:\n",
        "    if label == 'dog':\n",
        "      labels.append(np.array([1, 0]))\n",
        "    else:\n",
        "      labels.append(np.array([0, 1]))\n",
        "  return np.array(labels)\n",
        "\n",
        "def one_hot_encoding(input):\n",
        "  output = np.zeros((input.size, input.max()+1))\n",
        "  output[np.arange(input.size), input] = 1\n",
        "\n",
        "  return output\n",
        "\n",
        "def load_data():\n",
        "  # Run this cell to download our data into a file called 'cifar_data'\n",
        "  !wget -q --show-progress -O cifar_data https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%204%20_%205%20-%20Neural%20Networks%20_%20CNN/dogs_v_roads\n",
        "\n",
        "  # now load the data from our cloud computer\n",
        "  import pickle\n",
        "  with open(\"cifar_data\", \"rb\") as f:\n",
        "      data_dict = pickle.load(f)\n",
        "\n",
        "  data   = data_dict['data']\n",
        "  labels = data_dict['labels']\n",
        "\n",
        "  return data, labels\n",
        "\n",
        "def plot_one_image(data, labels, img_idx):\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  img   = data[img_idx, :].reshape([32,32,3]).copy()\n",
        "  label = labels[img_idx]\n",
        "\n",
        "  fig, ax = plt.subplots(1,1)\n",
        "  img = ax.imshow(img.astype('uint8'), extent=[-1,1,-1,1])\n",
        "\n",
        "  x_label_list = [0, 8, 16, 24, 32]\n",
        "  y_label_list = [0, 8, 16, 24, 32]\n",
        "\n",
        "  ax.set_xticks([-1, -0.5, 0, 0.5, 1])\n",
        "  ax.set_yticks([-1, -0.5, 0, 0.5, 1])\n",
        "\n",
        "  ax.set_xticklabels(x_label_list)\n",
        "  ax.set_yticklabels(y_label_list)\n",
        "\n",
        "  ax.set_title(f'Image: {img_idx} | Label: {label}')\n",
        "\n",
        "  display(fig)\n",
        "  plt.close(fig)\n",
        "\n",
        "def plot_acc(history, ax=None, xlabel='Epoch #'):\n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')\n",
        "    ax.legend(loc = 'best')\n",
        "    ax.set_ylim([0.4, 1.005])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def logits_to_one_hot_encoding(input):\n",
        "    \"\"\"\n",
        "    Converts softmax output (logits) to a one-hot encoded format.\n",
        "\n",
        "    This function takes an array of softmax output probabilities\n",
        "    (usually from a neural network's output layer) and converts\n",
        "    each row to a one-hot encoded vector. The highest probability\n",
        "    in each row is marked as 1, with all other values set to 0.\n",
        "\n",
        "    Parameters:\n",
        "    input (numpy.ndarray): A 2D array where each row contains softmax probabilities for each class.\n",
        "                            The shape of the array is (n_samples, n_classes).\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: A 2D array of the same shape as the input, where each row is the one-hot encoded representation\n",
        "                   of the class with the highest probability in the original row.\n",
        "    \"\"\"\n",
        "\n",
        "    output = np.zeros_like(input, dtype=int)\n",
        "    output[np.arange(len(input)), np.argmax(input, axis=1)] = 1\n",
        "    return output\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# CUSTOM CNN CLASS\n",
        "#-------------------------------------------------------------------------------\n",
        "class CNNClassifier:\n",
        "    \"\"\"\n",
        "    A Convolutional Neural Network (CNN) classifier using Keras, customized for binary classification tasks.\n",
        "\n",
        "    This class wraps a Keras Sequential model with a specific architecture suitable for image classification tasks.\n",
        "    It includes a custom `predict` method that outputs one-hot encoded predictions, and other standard Keras model\n",
        "    methods are accessible as well. This was done to override the need for the SciKeras wrappers that is frequently\n",
        "    incompatible with Google Colab versions of Keras & Tensorflow. Feel free to modify as needed.\n",
        "\n",
        "    Attributes:\n",
        "        num_epochs (int): The number of training epochs.\n",
        "        layers (int): The number of convolutional layers in the model.\n",
        "        dropout (float): The dropout rate used in dropout layers for regularization.\n",
        "        model (keras.models.Sequential): The underlying Keras Sequential model.\n",
        "\n",
        "    Methods:\n",
        "        build_model(): Constructs the CNN model with the specified architecture and compiles it.\n",
        "\n",
        "        fit(*args, **kwargs): Trains the model. Accepts arguments compatible with the Keras `fit` method.\n",
        "\n",
        "        predict(*args, **kwargs): Predicts labels for the input data. Converts the softmax output of the model\n",
        "                                  to one-hot encoded format using `logits_to_one_hot_encoding`. Necessary to match\n",
        "                                  accuracy_score function expected arguments.\n",
        "\n",
        "        predict_proba(*args, **kwargs): Predicts labels for the input data and returns the raw output of the softmax.\n",
        "                                        Used when wanting to inspect the raw probabilistic scoring of the model.\n",
        "\n",
        "    Usage:\n",
        "        cnn_classifier = CNNClassifier(num_epochs=30, layers=4, dropout=0.5)\n",
        "        cnn_classifier.fit(X_train, y_train)\n",
        "        predictions = cnn_classifier.predict(X_test)\n",
        "\n",
        "    Note:\n",
        "        The `__getattr__` method is overridden to delegate attribute access to the underlying Keras model,\n",
        "        except for the `predict` method which is customized.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_epochs=30, layers=4, dropout=0.5):\n",
        "        self.num_epochs = num_epochs\n",
        "        self.layers = layers\n",
        "        self.dropout = dropout\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Reshape((32, 32, 3)))\n",
        "\n",
        "        for i in range(self.layers):\n",
        "          model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "          model.add(Activation('relu'))\n",
        "\n",
        "        model.add(Conv2D(32, (3, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(self.dropout))\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Conv2D(64, (3, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(self.dropout))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(self.dropout))\n",
        "        model.add(Dense(2))\n",
        "        model.add(Activation('softmax'))\n",
        "        opt = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self, *args, **kwargs):\n",
        "        return self.model.fit(*args, epochs=self.num_epochs, batch_size=10, verbose=2, **kwargs)\n",
        "\n",
        "    # NOTE: WRITTEN TO RETURN ONE HOT ENCODINGS FOR ACCURACY\n",
        "    def predict(self, *args, **kwargs):\n",
        "        predictions = self.model.predict(*args, **kwargs)\n",
        "        return logits_to_one_hot_encoding(predictions)\n",
        "\n",
        "    def predict_proba(self, *args, **kwargs):\n",
        "        predictions = self.model.predict(*args, **kwargs)\n",
        "        return predictions\n",
        "\n",
        "    def score(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        return accuracy_score(y, predictions)\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        if name != 'predict' and name != 'predict_proba':\n",
        "            return getattr(self.model, name)\n",
        "        else:\n",
        "            raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyVA1_5IWYKg"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "You can find a more detailed Table of Contents by clicking on the icon on the left sidebar that looks like this: <img src=\"https://drive.google.com/uc?export=view&id=1AGUz4POrRWu_6n5yI_YdO4qFRr41_PzE\" width=20>.\n",
        "\n",
        ">[üìä Milestone 1: Review of the Dataset](#scrollTo=1QxGsnvhnn8R)\n",
        "\n",
        ">[üñºÔ∏è Milestone 2: CNNClassifier](#scrollTo=37O_VE_D1Bdy)\n",
        "\n",
        ">>[Training and Validation Curves](#scrollTo=c-XRh5Y5P_CL)\n",
        "\n",
        ">[üî® Milestone 3: Building Neural Networks from Scratch in Keras](#scrollTo=76z4NAY6afd7)\n",
        "\n",
        ">[üèó Milestone 4: Building a CNN Using Keras!](#scrollTo=QCbD6siv-Ip-)\n",
        "\n",
        ">>[Optional Reference: Understanding Hyperparameters in CNNs](#scrollTo=f5Vi6h06HZXZ)\n",
        "\n",
        ">[(Optional Challenge) üêà Milestone 5: Cats vs. Dogs with CNN](#scrollTo=z6BekoxKVq0G)\n",
        "\n",
        ">>[Advanced Challenge: Implementing a Famous Architecture for Cats vs. Dogs](#scrollTo=m6sFSGEqjPwe)\n",
        "\n",
        ">>[From AlexNet to VGGNet: A Better Choice for Image Classification](#scrollTo=ePRiJhGdEgQL)\n",
        "\n",
        ">[ü§î Knowledge Check](#scrollTo=JY2JwKkIVe53)\n",
        "\n",
        "\n",
        ">[üìã Cheat Sheets](#scrollTo=zreklStpVNcW)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QxGsnvhnn8R"
      },
      "source": [
        "---\n",
        "---\n",
        "# **üìä Milestone 1: Review of the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btr24O6Hqgo6"
      },
      "source": [
        "Once again, let's load in our dog/road dataset and create our training and test set. **What's the shape of each dataset? Why?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmZbrZoKnthN"
      },
      "outputs": [],
      "source": [
        "# Load our data\n",
        "data_raw, labels_raw = load_data()\n",
        "data = data_raw.astype(float)\n",
        "labels = categorical_to_numpy(labels_raw)\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(data, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "### WRITE YOUR CODE BELOW: Print the image data and its shape using the shape attribute!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcZra2S0NNSZ"
      },
      "source": [
        "Use the cell below as a reminder of what the data looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B83F3CmPNSux"
      },
      "outputs": [],
      "source": [
        "plot_one_image(data_raw, labels_raw, 300) # Play around with the number!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37O_VE_D1Bdy"
      },
      "source": [
        "---\n",
        "---\n",
        "# **üñºÔ∏è Milestone 2: CNNClassifier**\n",
        "\n",
        "> Note: This section goes over the CNNClassifier covered at the end of the neural networks notebook in more depth, including exploring hyperparameters!\n",
        "\n",
        "> While this section is a good warm-up for the more complex code later, you can feel free to go through this quickly to have more time to build custom neural networks, especially since hyperparameters are also covered in more depth later. Make sure you understand the training and validation curves before moving to other milestones though!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9qPFLOkGSVN"
      },
      "source": [
        "### 2.1.1. Coding Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqrfI4JiVeFr"
      },
      "source": [
        "As you know, there is a famous type of neural network known as convolutional neural networks (CNNs). These types of neural networks work particularly well on problems to do with computer vision. Let's try one out!\n",
        "\n",
        "To load up a simple CNN, just run the following! The `CNNClassifier` is a custom class we've built for you that mimics the behavior of the scikit-learn models you're used to. Feel free to check out the set-up cell to see how it's built, especially after you've finished up building your Keras models later in the notebook!\n",
        "\n",
        "```python\n",
        "cnn = CNNClassifier(num_epochs, layers, dropout)\n",
        "```\n",
        "\n",
        "Here are some quick descriptions of each parameter; try to figure out how each might affect the model's performance!\n",
        "\n",
        "- **`num_epochs`**: the number of times we allow our model to train on the entire training dataset\n",
        "- **`layers`**: the number of convolutional layers we'd like to add to our model\n",
        "- **`dropout`**: the probability a given neuron's weight in a given layer is set to 0 during training.\n",
        "\n",
        "\n",
        "**Try different values of num_epochs, layers, and dropout so that you get the best possible accuracy on the test set!**\n",
        "\n",
        "*Tip*: You can use `model.score()` to find that accuracy, as we do below. This method allows us to give all the test data to the model for it to determine the accuracy score, thereby saving us the trouble of saving the predictions and calculating the score ourselves!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmC3-T4KRJgW"
      },
      "outputs": [],
      "source": [
        "# Create and train our CNN model\n",
        "cnn = CNNClassifier(num_epochs=5, layers=2, dropout=0.5)\n",
        "cnn.fit(X_train, y_train)\n",
        "\n",
        "# Print the score on the testing data\n",
        "print(cnn.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGWpgsVXP1ut"
      },
      "source": [
        "**How well did your neural network perform?**\n",
        "\n",
        "CNNs typically perform better than fully-connected neural networks on vision problems, but, as before, they aren't always consistent. They are also sensitive to a number of parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-XRh5Y5P_CL"
      },
      "source": [
        "## Training and Validation Curves\n",
        "\n",
        "An important aspect of training neural networks is to prevent overfitting. **How would we recognize overfitting?**\n",
        "\n",
        "In the first line of code below, we first **fit** the model on the training data and pass in some validation (or test) data to evaluate it. We call it the **history** because we want to retain information about the accuracy at each epoch.\n",
        "\n",
        "In the second line we plot the history so that we can compare the training and validation accuracies.  \n",
        "\n",
        "```python\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test))\n",
        "plot_acc(history)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eaFvE2PQEFe"
      },
      "source": [
        "### 2.1.2. Coding Exercise\n",
        "\n",
        "**After how many epochs does the model begin to overfit? How does this vary as you vary the number of hidden layers and dropout?** Overfitting occurs when the validation accuracy starts to drop below the training accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsVAasDbjARJ"
      },
      "outputs": [],
      "source": [
        "### WRITE YOUR CODE BELOW\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zEYUz17TJCGX"
      },
      "outputs": [],
      "source": [
        "# Print the score on the testing data\n",
        "print(\"CNN Testing Set Score:\")\n",
        "print(cnn.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76z4NAY6afd7"
      },
      "source": [
        "---\n",
        "---\n",
        "# **üî® Milestone 3: Building Neural Networks from Scratch in Keras**\n",
        "\n",
        "So far, we've used our helper class which pre-builds a Keras neural network model. Now, we can build them on our own!\n",
        "\n",
        "Let's start with a \"toy example\": a tiny neural network with just three numerical inputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdngkAX_aCVu"
      },
      "source": [
        "### 3.1.1. Coding Exercise\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj-Pt3wGCXRu"
      },
      "source": [
        "We're going to build this simple model:\n",
        "\n",
        "<center>\n",
        "<img src=\"http://cs231n.github.io/assets/nn1/neural_net.jpeg\">\n",
        "</center>\n",
        "\n",
        "This network can be described as:\n",
        "* Input Layer: 3 neurons\n",
        "* Layer 1 (Hidden): 4 neurons that are activated by `'relu'`\n",
        "* Layer 2 (Output): 2 neurons that are activated by `'softmax'`\n",
        "\n",
        "\n",
        "We also want to compile the model with\n",
        "`loss = 'categorical_crossentropy'`\n",
        "\n",
        "What does this represent? Here's one way to interpret it:\n",
        "* This model classifies animals as \"cat\" or \"dog\"\n",
        "* Our three inputs are height, weight, and age\n",
        "* Our outputs represent \"probability of cat\" and \"probability of dog\"\n",
        "* Because this is a toy example, we aren't actually training the model here - just using randomly initialized weights! We will train later models in this notebook.\n",
        "\n",
        "Try looking at the template code below! Uncomment one line at a time and fill in each blank, and make sure you understand which line goes with which part of the above structure. **If you want a hint or more details, check out the optional reference below.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dp-g9qotbRPU"
      },
      "outputs": [],
      "source": [
        "### WRITE YOUR CODE BELOW: delete the #s and fill in the blanks!\n",
        "\n",
        "# model_1 = Sequential()\n",
        "# model_1.add(InputLayer(shape=(____,)))\n",
        "# model_1.add(Dense(____, activation='____'))\n",
        "# model_1.add(Dense(____, activation='____'))\n",
        "# model_1.compile(loss='____', optimizer='adam', metrics=['accuracy'])\n",
        "# model_1.predict(np.array([[14, 18, 5]])) # Try any input! This represents an animal of height 14, weight 18, and age 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baWZ9zXtF2Cz"
      },
      "source": [
        "### 3.1.2. Discussion Exercise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "-WvOFhAPFYML"
      },
      "outputs": [],
      "source": [
        "#@markdown *How would you interpret this output? Does our (untrained) network classify this as a cat or a dog?*\n",
        "answer = \"\" # @param {\"type\":\"string\"}\n",
        "handle_discussion_response(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqVZ6FNiFAfY"
      },
      "source": [
        "### *(Optional) Reference: Basic Keras Sequential Models*\n",
        "> Take a look at this section if you want more information on how a Keras Sequential model is built!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p82IouQE-2F"
      },
      "source": [
        "\n",
        "\n",
        "Here's some information about each step of the process. **You don't need to read through all this - check it as a reference if needed!**\n",
        "\n",
        "#### **1. Specify model**\n",
        "\n",
        "```python\n",
        "model = Sequential()\n",
        "```\n",
        "\n",
        "In this line of code, we build our network where the information flows from LEFT to RIGHT through the network in ONE DIRECTION sequentially as opposed to multiple directions. Neurons on the right never pass informations to neurons on the left of it.\n",
        "\n",
        "\n",
        "#### **2. Add layers to the network**\n",
        "```python\n",
        "model.add(InputLayer(shape=(5,)))\n",
        "```\n",
        "\n",
        "In this code, we add the input layer to the model. Here, we specify that there is a 1-dimensional list of 5 values as input.\n",
        "\n",
        "```python\n",
        "model.add(Dense(4, activation='sigmoid'))\n",
        "```\n",
        "\n",
        "In this code, we add a layer of 4 neurons to our network. Each neuron is DENSE and connects to all of the previous layer's inputs and all of the subsequent layer's outputs.\n",
        "\n",
        "We also specify what kind of output the neuron will give. If you want the neuron to output a number between 0 and 1 (like a probability!) you would use `'softmax'` or `'sigmoid'`. If you want the neuron to output any number, you can use `'linear'`! You'll also often see `'relu'`, which is when a neuron will only output nonnegative numbers.\n",
        "\n",
        "```python\n",
        "model.add(Dense(1, activation='linear'))\n",
        "```\n",
        "\n",
        "This code would add ANOTHER layer to the network that has 1 neuron. Since this would be our last layer in this example, this one neuron is used to predict a continuous value!\n",
        "\n",
        "#### **3. Turn the model on by compiling it**\n",
        "\n",
        "After having built the network, we want to train and use it, so we have to 'compile' it to prepare. We have to specify at the very least: a loss (how the model measures the quality of its weights), an optimizer (which adjusts the weights), and a metric (how to evaluate our results). Here are some common choices:\n",
        "\n",
        "```python\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mean_squared_error'])\n",
        "```\n",
        "\n",
        "Once we've created our network, we can use it very simply! Just like we did with sklearn, we define our input data (`X`), the true predictions from that data (`y`), and then train our model with `fit`.\n",
        "\n",
        "```\n",
        "model.fit(X, y)\n",
        "```\n",
        "\n",
        "To use the model, you can use it to predict something with:\n",
        "\n",
        "```\n",
        "y_pred = model.predict(X)\n",
        "```\n",
        "\n",
        "You can actually use the model before you even train it! It just won't perform very well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0_ukK9WN4d9"
      },
      "source": [
        "### *(Optional) Reference: Neural Network Math: ReLU vs. Softmax*\n",
        "> This section delves a bit more into the math behind some of the activation functions from above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ARxmqT1N1MN"
      },
      "source": [
        "\n",
        "As you've seen already two commonly used activation functions are ReLU (Rectified Linear Unit) and Softmax, each serving distinct purposes in neural networks.\n",
        "\n",
        "#### **ReLU (Rectified Linear Unit)**\n",
        "- **Usage**: ReLU is primarily used in the hidden layers of neural networks.\n",
        "- **Function**: It outputs the input directly if it is positive; otherwise, it will output zero. Mathematically, it's defined as\n",
        "\n",
        "$$ f(x) = \\max(0, x) $$\n",
        "\n",
        "- **Advantages**:\n",
        "  - Helps in speeding up the training process by overcoming the vanishing gradient problem common with other activation functions like sigmoid or tanh.\n",
        "  - It introduces non-linearity into the network, allowing it to learn more complex patterns.\n",
        "\n",
        "#### **Softmax**\n",
        "- **Usage**: Softmax is typically used in the output layer of a classifier, where we need to handle multiple classes.\n",
        "- **Function**: Softmax converts logits (the raw output scores in logistic regression) into probabilities by taking the exponentials of each output and then normalizing these values by dividing by the sum of all exponentials. This gives a probability distribution across various classes that sums to 1. Mathematically, for each output $x_i$ in the layer, it's defined as\n",
        "\n",
        "$$ f(x_i) = \\frac{e^{x_i}}{\\sum e^{x_j}} $$\n",
        "  \n",
        "- **Advantages**:\n",
        "  - By outputting a probability distribution, it works well for classes that are mutually exclusive, making it ideal for multi-class classification problems.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgiA72h6FfVZ"
      },
      "source": [
        "### (Optional) 3.1.3. Coding Exercise\n",
        "> Try this out if you want more practice with building a slightly more complex model!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YovNRgfuy0Oq"
      },
      "source": [
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\">\n",
        "</center>\n",
        "\n",
        "Let's try another, bigger example!\n",
        "\n",
        "Here, we are predicting a house price: regression! Our inputs could be \"year the house was built\", \"home square footage\", and \"lot square footage\", while our output is price (in thousands of dollars).\n",
        "\n",
        "* Input Layer: 3 neurons\n",
        "* Layer 1: 4 neurons that are activated by `'relu' `\n",
        "* Layer 2: 4 neurons that are activated by `'relu'`\n",
        "* Layer 3 (out): 1 neuron that is activated by `'relu'`\n",
        "\n",
        "Compile the model with\n",
        "`'mean_squared_error'` as both loss and metric, and try making a prediction for some made-up data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pm-ylEWqbXrQ"
      },
      "outputs": [],
      "source": [
        "### WRITE YOUR CODE BELOW\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShCCG5aLF8za"
      },
      "source": [
        "### (Optional) 3.1.4. Coding Exercise\n",
        "> Try this out if you want to build an even more complex model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVCmntRHRjPQ"
      },
      "source": [
        "Let's try an even bigger example! Here, we are going to distinguish between images of dogs and roads once again.\n",
        "\n",
        "* Input Layer: 3072 neurons (32 pixels x 32 pixels x 3 color channels)\n",
        "\n",
        "* Layer 1: 32 neurons that are activated by `'relu' `and take in 3072 inputs.\n",
        "\n",
        "* Layer 2: 16 neurons that are activated by `'relu'`\n",
        "\n",
        "* Layer 3 (out): 2 neurons that are activated by `'softmax'`\n",
        "\n",
        "Compile the model with\n",
        "`loss='categorical_crossentropy'`, and try making predictions on `X_train`!\n",
        "\n",
        "Once again, we are not actually training this model - so the predictions won't be any good. Soon we will create a CNN, which we will train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DD2Dc4AYR31r"
      },
      "outputs": [],
      "source": [
        "### WRITE YOUR CODE BELOW\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCbD6siv-Ip-"
      },
      "source": [
        "---\n",
        "---\n",
        "# **üèó Milestone 4: Building a CNN Using Keras!**\n",
        "\n",
        "Now that we know how to build simple neural networks in Keras, let's build a CNN! The CNN will perform well on our data set of car and road images.\n",
        "\n",
        "Below is Keras code for a CNN. It will run as-is on the conscientious cars dataset. However, the performance is suboptimal. Add more layers and change the neural network hyperparameters so that the performance will be better. **Can you get the train and validation accuracy to both be higher than 95%?**\n",
        "\n",
        "The Keras core layer API may be a useful reference: https://keras.io/layers/core/\n",
        "\n",
        "In particular and in addition to adding more of the existing convolutional layers and activations, consider using the following layers after a convolution + activation. Can you take a guess at what they'd be doing for a given input?\n",
        "\n",
        "```python\n",
        "Dropout(RATE)\n",
        "MaxPooling2D(pool_size=(N, N))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LFVHyPKn-V4N"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Reshape((32, 32, 3))) # Try to figure out why this layer is necessary!\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "###\n",
        "### WRITE YOUR CODE BELOW: Add more layers!\n",
        "###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###\n",
        "### END CODE HERE\n",
        "###\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the CNN and plot accuracy.\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=70)\n",
        "plot_acc(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JFLu0CdXM6K"
      },
      "source": [
        "**What interesting observations** do you make from the graph? How many epochs should you train for?\n",
        "\n",
        "We can also print out the structure of our model. What do the parts of the summary mean?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGwXs3C8YZl-"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5Vi6h06HZXZ"
      },
      "source": [
        "## *(Optional) Reference: Understanding Hyperparameters in CNNs*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e53j15ffHX2V"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "This reference section delves into the hyperparameters used in our convolutional neural networks (CNNs) and explains how adjustments to these parameters can affect model performance. Each component is exemplified by snippets from the CNN models you're working with in this notebook.\n",
        "\n",
        "### **Core Configuration of the CNN Model**\n",
        "In our first model configuration:\n",
        "```python\n",
        "model.add(Conv2D(96, 11, strides=3))\n",
        "model.add(Activation('relu'))\n",
        "...\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "```\n",
        "- **Number of Filters and Kernel Size**: Starting with 96 filters using an 11x11 kernel size demonstrates capturing broader features initially, which is useful for input images with higher dimensionality.\n",
        "- **Strides**: Setting strides to 3 helps reduce the dimensionality of the output, speeding up computation.\n",
        "- **Activation Function**: 'ReLU' is used for adding non-linearity, helping the network learn complex patterns, while 'softmax' in the output layer facilitates a probability distribution among the classes.\n",
        "\n",
        "### **Optimizer and Learning Rate**\n",
        "In the model setup, the RMSprop optimizer with a learning rate of 0.0001 is chosen:\n",
        "```python\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
        "```\n",
        "- **Learning Rate**: The low learning rate allows for finer adjustments in weights, potentially leading to better convergence at the cost of requiring more epochs.\n",
        "\n",
        "### **Advanced Model Example Using Transfer Learning**\n",
        "In a different approach using the VGG16 architecture:\n",
        "```python\n",
        "model = VGG16(include_top=False, shape=(224, 224, 3))\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "...\n",
        "model.compile(optimizer=SGD(learning_rate=0.001, momentum=0.9), ...)\n",
        "```\n",
        "- **Transfer Learning**: The use of VGG16, a pre-trained network, as a feature extractor (with non-trainable layers) illustrates leveraging learned features from vast datasets, which can be advantageous for specific applications.\n",
        "- **SGD Optimizer**: Employing Stochastic Gradient Descent (SGD) with momentum emphasizes more robust convergence, particularly in fine-tuning scenarios.\n",
        "\n",
        "### **Training and Validation**\n",
        "Our training sessions are configured as follows:\n",
        "```python\n",
        "history = model.fit(...)\n",
        "plot_acc(history)\n",
        "```\n",
        "- **Epochs and Batch Size**: Adjusting these according to the dataset size and complexity of the model influences both training speed and accuracy. Fewer epochs in the VGG16 example indicate a quicker adaptation phase due to pre-learned features.\n",
        "\n",
        "### **Practical Tips**\n",
        "- **Experiment**: Vary these hyperparameters to see their impact firsthand.\n",
        "- **Balance**: Consider the trade-offs between training speed and accuracy.\n",
        "- **Validation**: Always use a separate validation set to assess model generalization.\n",
        "\n",
        "Feel free to modify these segments according to your experiment needs and observe how changes affect your model's learning curve and performance. See the next section for more concrete examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKn71BjrHyRu"
      },
      "source": [
        "### (Optional) Reference: More on Hyperparameters!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmiddQpFHujX"
      },
      "source": [
        "\n",
        "Below, we explore these parameters through practical examples directly applied in Keras.\n",
        "\n",
        "#### 1. **Number of Layers**\n",
        "   - **Impact**: More layers allow a CNN to learn more complex features at different levels of abstraction. For example, deeper layers in models like VGG16 are adept at recognizing high-level features in images.\n",
        "   - **Example**: `model.add(Conv2D(32, (3, 3)))` followed by multiple similar layers.\n",
        "\n",
        "#### 2. **Number of Filters**\n",
        "   - **Impact**: Each filter detects different features, and having more filters increases the network's capacity to learn diverse features.\n",
        "   - **Example**: Starting with `model.add(Conv2D(32, (3, 3)))` and increasing to `model.add(Conv2D(64, (3, 3)))` in subsequent layers.\n",
        "\n",
        "#### 3. **Filter Size**\n",
        "   - **Impact**: Smaller filters (e.g., 3x3) are excellent for capturing small detail, while larger filters (e.g., 5x5) capture wider patterns.\n",
        "   - **Example**: `model.add(Conv2D(64, (3, 3)))` for fine detail versus `model.add(Conv2D(64, (5, 5)))` for broader features.\n",
        "\n",
        "#### 4. **Stride**\n",
        "   - **Impact**: Strides affect how the filter moves across the image; larger strides reduce the output size.\n",
        "   - **Example**: `model.add(Conv2D(64, (3, 3), strides=(2, 2)))`, reducing spatial dimensions more rapidly.\n",
        "\n",
        "#### 5. **Padding**\n",
        "   - **Impact**: 'Same' padding ensures the output has the same width and height as the input, while 'valid' does not add zero padding.\n",
        "   - **Example**: `model.add(Conv2D(64, (3, 3), padding='same'))` keeps dimensions intact.\n",
        "\n",
        "#### 6. **Activation Function**\n",
        "   - **Impact**: Determines how neurons fire. Commonly used ReLU is effective for non-linear problems.\n",
        "   - **Example**: `model.add(Activation('relu'))` typically follows each convolutional layer.\n",
        "\n",
        "#### 7. **Pooling Layer**\n",
        "   - **Impact**: Reduces dimensionality, thus controlling overfitting and reducing computational load.\n",
        "   - **Example**: `model.add(MaxPooling2D((2, 2)))` often follows one or more convolutional layers.\n",
        "\n",
        "#### 8. **Learning Rate**\n",
        "   - **Impact**: A crucial factor in convergence speed. Too high can overshoot minimum; too low may result in a long training process.\n",
        "   - **Example**: `optimizer = keras.optimizers.Adam(learning_rate=0.001)`\n",
        "\n",
        "#### 9. **Batch Size**\n",
        "   - **Impact**: Affects the memory footprint and can influence the model's generalization.\n",
        "   - **Example**: `model.fit(x_train, y_train, batch_size=64)`\n",
        "\n",
        "#### 10. **Epochs**\n",
        "   - **Impact**: More epochs generally lead to a better fit, provided early stopping is used to prevent overfitting.\n",
        "   - **Example**: `model.fit(x_train, y_train, epochs=20)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6BekoxKVq0G"
      },
      "source": [
        "---\n",
        "---\n",
        "# **(Optional Challenge) üêà Milestone 5: Cats vs. Dogs with CNN**\n",
        "\n",
        "> Try this section out to solve a more complex problem: categorizing images as dogs or cats!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXINPAJvRr9W"
      },
      "source": [
        "\n",
        "\n",
        "So far, we've trained a CNN to distinguish between small images of roads and small images of dogs. It's more challenging and time-consuming to train CNNs for bigger images or harder tasks, like distinguishing dogs from cats (which look a lot more like dogs than roads do!)\n",
        "\n",
        "In this exercise, you'll adapt your previous model to classify large images of dogs vs. cats, and then try implementing a famous CNN architecture. Along the way, you'll deal with some of the debugging that machine learning engineers often have to handle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gU39z3jNMAt"
      },
      "outputs": [],
      "source": [
        "#@title Run this to load cat and dog data! {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "\n",
        "# Code here from https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb#scrollTo=4PIP1rkmeAYS\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "  road_model = model\n",
        "  road_saved = True\n",
        "except NameError:\n",
        "  road_saved = False\n",
        "\n",
        "IMG_SHAPE  = 150  # Our training data consists of images with width of 150 pixels and height of 150 pixels\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin=_URL, extract=True)\n",
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered_extracted/cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "train_image_generator      = ImageDataGenerator()  # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator()  # Generator for our validation data\n",
        "train_data = next(train_image_generator.flow_from_directory(batch_size=2000,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "                                                           class_mode='binary'))\n",
        "val_data = next(validation_image_generator.flow_from_directory(batch_size=1000,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              shuffle=False,\n",
        "                                                              target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "\n",
        "                                                              class_mode='binary'))\n",
        "cd_train_inputs, cd_train_labels = train_data\n",
        "cd_test_inputs, cd_test_labels = val_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y5etOJwScaG"
      },
      "source": [
        "**Run the code below to see the dimensions of our training and validation data. What does each number mean? What is different than our previous dataset?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjdedJ0VNvWg"
      },
      "outputs": [],
      "source": [
        "print(cd_train_inputs.shape)\n",
        "print(cd_train_labels.shape)\n",
        "print(cd_test_inputs.shape)\n",
        "print(cd_test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIAkgOqWTAL7"
      },
      "source": [
        "**Run this code to see a random image from our training data (different each time).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HooiJ-RrQPcA"
      },
      "outputs": [],
      "source": [
        "index = np.random.randint(len(cd_train_inputs))\n",
        "plt.imshow(cd_train_inputs[index] / 255)\n",
        "plt.show()\n",
        "print(\"Label:\", cd_train_labels[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOwP9kX9UshH"
      },
      "source": [
        "**By adapting code from the previous exercise, build, train, and test a CNN to classify cats vs. dogs.**\n",
        "**Hints:**\n",
        "*   Use `model.summary()` for a useful visualization of your model's architecture. Compare the summary of your cat/road and cat/dog classifiers.\n",
        "*  Substitute the names of the new datasets.\n",
        "*  Get a \"first try\" working by making small adjustments to a previous model before trying to optimize the accuracy. You can temporarily comment out layers as you figure things out.\n",
        "*  The outputs have different shapes betweeen the two datasets. What do you need to change? (You will get a ValueError that suggests how to transform the output to a one-hot encoding. Hint: you may want to look into how to use the `to_categorical()` function)\n",
        "*  If you run out of memory, restart the notebook and/or use your knowledge of convolution arithmetic to reduce the size of an intermediate output (see [Keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)).\n",
        "* Dropout layers help reduce overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeuqlzigZZ8I"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "# TODO: Your code here to build, train, and test a cats vs. dogs CNN! (If you run into errors, see the hints above for help debugging!)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6sFSGEqjPwe"
      },
      "source": [
        "## Advanced Challenge: Implementing a Famous Architecture for Cats vs. Dogs\n",
        "\n",
        "Having trouble designing an effective architecture? Try implementing a version of AlexNet, one of the most famous CNNs for image convolution ever. You can find this image and other useful information on this network [here](https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96).\n",
        "\n",
        "![](https://lh4.googleusercontent.com/gFAxn9Z-Y1lgkNy2GfsqjXy1DvSuYF8rvP3CslRvmuoP5SUaJMrEOr24YShU_LwalLpYNJFwpJgcDh9whk9XrMOGQ1ADQ9FY_0saicCVH0jsNPDKOYBcTG4YhbqpbPolW4hZSdUsDQ)\n",
        "\n",
        "How do we read this diagram?\n",
        "\n",
        "On the left side, we start with images of dimension 227x227x3 (RGB). We apply a filter composed of 96 kernels of size 11x11, with stride size 4. We end up with data of dimension 55x55x96. We pass through multiple layers of convolution and max pooling as shown, before ending with three dense (fully connected) layers.\n",
        "\n",
        "Not shown: each layer uses ReLU activation, and we include dropout before the first two dense layers. Make sure to include those!\n",
        "\n",
        "You'll want to adjust some of these dimensions, for a few reasons: we're starting with 150x150 rather than 227x227 images, ending with 2 labels rather than 1000, and have limited data and memory. Use your knowledge of convolution arithmetic (see CNN slides) and the [Keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) to change the stride, kernel, and/or padding.\n",
        "\n",
        "Use `model.summary()` to understand the dimensions of your data at each step. To speed things up as you're building, you can set the number of epochs to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FHg8YTGtQ2t"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "### WRITE YOUR CODE BELOW: Run, train, and test AlexNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlF308hDjwyC"
      },
      "source": [
        "You might find that even AlexNet isn't working that well for you!\n",
        "\n",
        "This is because having a good architecture is only half the battle: AlexNet is a complex model designed to learn from millions of images. We're using a small dataset of only 2000 training images, so it's not surprising that our results aren't great. Our model is overfitting: essentially memorizing the few training images, rather than really learning the difference between a cat and a dog. (The advantage is that our model trains quickly.)\n",
        "\n",
        "To get really good performance, we need more data. If we can't find more, we could use *data augmentation*: inventing new training data by transforming our existing images. You can read more about it at https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePRiJhGdEgQL"
      },
      "source": [
        "## From AlexNet to VGGNet: A Better Choice for Image Classification\n",
        "\n",
        "AlexNet's architecture may not be complex enough to capture the nuanced differences between cats and dogs, which might result in lower accuracy in classification tasks.\n",
        "\n",
        "VGGNet, or simply VGG, introduced by the Visual Geometry Group, is a much deeper model with its variants VGG16 and VGG19 having 16 and 19 layers respectively. VGG architecture has smaller, but more number of convolutional filters compared to AlexNet, allowing it to learn more complex features. This depth, along with the use of small 3x3 filters throughout the network, makes it excellent at learning hierarchical features in images, making it more suitable for our cat versus dog classification task.\n",
        "\n",
        "Moreover, VGG models have been trained on millions of images from the ImageNet\n",
        "database, which includes a wide variety of animal images, making the learned features more generalized and better suited for our task. Hence, moving from AlexNet to VGG for our specific classification task would be a strategic choice to potentially improve our model's performance.\n",
        "\n",
        "So let's see how good it is at our task!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de8Dp3x9Eqgb"
      },
      "outputs": [],
      "source": [
        "#@title Run this to load images and imports! {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "\n",
        "train_data = next(train_image_generator.flow_from_directory(batch_size=2000,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(224,224), #(150,150)\n",
        "                                                           class_mode='binary'))\n",
        "val_data = next(validation_image_generator.flow_from_directory(batch_size=1000,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              shuffle=False,\n",
        "                                                              target_size=(224,224), #(150,150)\n",
        "                                                              class_mode='binary'))\n",
        "cd_train_inputs, cd_train_labels = train_data\n",
        "cd_test_inputs, cd_test_labels = val_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxBngnvRFaDf"
      },
      "source": [
        "It's crucial to note that VGG16 model requires input images to have a size of 224x224 pixels. We've already preprocessed our images to match this requirement, but ensure the model's input shape is set to this dimensionality as well!\n",
        "\n",
        "Also, you might have noticed that there's another dimension specified in the model's input shape. Wondering what that is? It's the channel dimension. For colored images, it is usually 3, representing the Red, Green, and Blue channels.\n",
        "\n",
        "Now, let's move onto our model configuration. For the first Dense layer, we will be using the 'relu' (Rectified Linear Unit) activation function. It's a commonly used activation function that introduces non-linearity in our model.\n",
        "\n",
        "Following that, we'll utilize the 'sigmoid' activation function in our final Dense layer. The sigmoid function squashes the output between the range of 0 and 1, making it suitable for binary classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhkQWKVxEuGF"
      },
      "outputs": [],
      "source": [
        "###\n",
        "### WRITE YOUR CODE BELOW: Fill in the blanks!\n",
        "###\n",
        "\n",
        "# Load the VGG16 model without the top (classifier) layers\n",
        "base_model = VGG16(include_top=False, input_shape=(______,______,______))\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classifier on top\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(128, activation='______', kernel_initializer='he_uniform')(x)\n",
        "output = Dense(2, activation='______')(x)\n",
        "\n",
        "###\n",
        "### END CODE HERE\n",
        "###\n",
        "\n",
        "\n",
        "# Define new model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile model\n",
        "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    cd_train_inputs, to_categorical(cd_train_labels),\n",
        "    validation_data=(cd_test_inputs, to_categorical(cd_test_labels)),\n",
        "    epochs=2\n",
        ")\n",
        "\n",
        "# Display training history and model structure\n",
        "plot_acc(history)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF1gDyE9NqpE"
      },
      "source": [
        "***You've reached the end!***\n",
        "\n",
        "Moving from AlexNet to VGGNet represents a shift towards more complex and powerful models. Don't feel discouraged if it feels overwhelming - the depth and complexity of VGGNet are part of its strength and why it performs so well.\n",
        "\n",
        "By experimenting with different hyperparameters, layers, and models you're not only enhancing your problem-solving skills but also your intuition about how neural networks operate.\n",
        "\n",
        "Remember, even if you don't hit 95% accuracy, the key is to learn from the process and understand why a certain setup works or why it doesn't.\n",
        "\n",
        "Keep up the fantastic work! Remember, the path to mastering machine learning is a marathon, not a sprint. Keep exploring, keep questioning, and most importantly, have fun with it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY2JwKkIVe53"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# **ü§î Knowledge Check**\n",
        "\n",
        "Great job getting through this notebook! If you have time, feel free to go back to the optional sections before this section to delve deeper.\n",
        "\n",
        "Feel free to use the below questions to ensure you've learned everything from this notebook!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9jhgqLU0VhOe"
      },
      "outputs": [],
      "source": [
        "#@markdown *1. How do we know if a model is overfitting using the training and validation curves?*\n",
        "answer_1 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *2. What is an activation function?*\n",
        "answer_2 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *3. How is a CNN different from a regular fully connected neural network?*\n",
        "answer_3 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *4. Categorical cross-entropy is an example of a loss function. What does a loss function do in a neural network?*\n",
        "answer_4 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer_1, answer_2, answer_3, answer_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF0R83Y5NT-X"
      },
      "source": [
        "If you went through the optional/advanced sections, you can try these questions out too!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8NkWu76HNSM_"
      },
      "outputs": [],
      "source": [
        "#@markdown *1. What's the difference between the ReLU and softmax activation functions?*\n",
        "answer_1 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *2. Why are the results from AlexNet and VGGNet better than what we were able to build ourselves?*\n",
        "answer_2 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer_1, answer_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zreklStpVNcW"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# **üìã Extra Resources**\n",
        "\n",
        "Feel free to use the following cheat sheet as a quick reference!\n",
        "\n",
        "- [Keras Cheat Sheet](https://docs.google.com/document/d/1NK3wvy9pnpg6vab6AkdzLwGSsNf31NSIsrEYz1IVljk/edit?pli=1&tab=t.izacw33yd6ek)\n",
        "\n",
        "\n",
        "The following resource should also be helpful in your understanding of CNNs:\n",
        "\n",
        "- [CNN Explainer](https://poloclub.github.io/cnn-explainer/)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "bqVZ6FNiFAfY",
        "G0_ukK9WN4d9",
        "VgiA72h6FfVZ",
        "f5Vi6h06HZXZ",
        "QKn71BjrHyRu"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}